{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Train Alert Recommendation Model\n",
    "\n",
    "This notebook trains the KNN-based collaborative filtering model for alert recommendations.\n",
    "\n",
    "**Inputs:**\n",
    "- User data from MinIO\n",
    "- Transaction data from MinIO\n",
    "\n",
    "**Outputs:**\n",
    "- Trained model saved as `model.pkl` in models directory\n",
    "- Model metadata saved as `model_metadata.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import boto3\n",
    "from botocore.client import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline parameters\n",
    "NAMESPACE = os.getenv('NAMESPACE', 'spending-transaction-monitor')\n",
    "BUCKET_NAME = os.getenv('BUCKET_NAME', 'models')\n",
    "DATA_VERSION = os.getenv('DATA_VERSION', '1')\n",
    "MODEL_VERSION = os.getenv('MODEL_VERSION', '1.0.0')\n",
    "N_NEIGHBORS = int(os.getenv('N_NEIGHBORS', '5'))\n",
    "METRIC = os.getenv('METRIC', 'cosine')\n",
    "\n",
    "# MinIO configuration (S3-compatible)\n",
    "MINIO_ENDPOINT = os.getenv('MINIO_ENDPOINT', f'http://minio-service.{NAMESPACE}.svc.cluster.local:9000')\n",
    "MINIO_ACCESS_KEY = os.getenv('MINIO_ACCESS_KEY', 'minio')\n",
    "MINIO_SECRET_KEY = os.getenv('MINIO_SECRET_KEY', 'minio123')\n",
    "\n",
    "print(f'Training configuration:')\n",
    "print(f'  MinIO Endpoint: {MINIO_ENDPOINT}')\n",
    "print(f'  Bucket: {BUCKET_NAME}')\n",
    "print(f'  Data Version: {DATA_VERSION}')\n",
    "print(f'  Model Version: {MODEL_VERSION}')\n",
    "print(f'  N Neighbors: {N_NEIGHBORS}')\n",
    "print(f'  Metric: {METRIC}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MinIO client (S3-compatible)\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=MINIO_ENDPOINT,\n",
    "    aws_access_key_id=MINIO_ACCESS_KEY,\n",
    "    aws_secret_access_key=MINIO_SECRET_KEY,\n",
    "    config=Config(signature_version='s3v4'),\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "print('âœ… MinIO client initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Load Data from MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from MinIO\n",
    "data_key_prefix = f'data/v{DATA_VERSION}'\n",
    "\n",
    "# Create temp directory\n",
    "os.makedirs('/tmp', exist_ok=True)\n",
    "\n",
    "# Load users data\n",
    "users_key = f'{data_key_prefix}/users.csv'\n",
    "try:\n",
    "    s3_client.download_file(BUCKET_NAME, users_key, '/tmp/users.csv')\n",
    "    users_df = pd.read_csv('/tmp/users.csv')\n",
    "    print(f'âœ… Loaded {len(users_df)} users from MinIO')\n",
    "except Exception as e:\n",
    "    print(f'âš ï¸  Could not load users from MinIO: {e}')\n",
    "    print(f'   Loading from local data directory instead...')\n",
    "    users_df = pd.read_csv('./data/users.csv')\n",
    "    print(f'âœ… Loaded {len(users_df)} users from local data')\n",
    "\n",
    "# Load transactions data\n",
    "transactions_key = f'{data_key_prefix}/transactions.csv'\n",
    "try:\n",
    "    s3_client.download_file(BUCKET_NAME, transactions_key, '/tmp/transactions.csv')\n",
    "    transactions_df = pd.read_csv('/tmp/transactions.csv')\n",
    "    print(f'âœ… Loaded {len(transactions_df)} transactions from MinIO')\n",
    "except Exception as e:\n",
    "    print(f'âš ï¸  Could not load transactions from MinIO: {e}')\n",
    "    print(f'   Loading from local data directory instead...')\n",
    "    transactions_df = pd.read_csv('./data/transactions.csv')\n",
    "    print(f'âœ… Loaded {len(transactions_df)} transactions from local data')\n",
    "\n",
    "# Load existing alerts (if available)\n",
    "try:\n",
    "    alerts_key = f'{data_key_prefix}/user_alerts.csv'\n",
    "    s3_client.download_file(BUCKET_NAME, alerts_key, '/tmp/user_alerts.csv')\n",
    "    user_alerts_df = pd.read_csv('/tmp/user_alerts.csv')\n",
    "    print(f'âœ… Loaded {len(user_alerts_df)} alert preferences')\n",
    "    use_real_alerts = True\n",
    "except:\n",
    "    print('â„¹ï¸  No alert preferences found - will use heuristic labels')\n",
    "    user_alerts_df = None\n",
    "    use_real_alerts = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_features(users_df, transactions_df):\n",
    "    \"\"\"Build behavioral features from transaction history\"\"\"\n",
    "    \n",
    "    # Convert amount to numeric\n",
    "    transactions_df['amount'] = pd.to_numeric(transactions_df['amount'], errors='coerce')\n",
    "    \n",
    "    # Aggregate transaction metrics per user\n",
    "    tx_agg = transactions_df.groupby('user_id').agg({\n",
    "        'amount': ['count', 'mean', 'std', 'max', 'sum'],\n",
    "        'merchant_name': pd.Series.nunique,\n",
    "        'merchant_category': pd.Series.nunique\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    tx_agg.columns = ['_'.join(col) if isinstance(col, tuple) else col for col in tx_agg.columns]\n",
    "    tx_agg = tx_agg.reset_index()\n",
    "    tx_agg.columns = ['user_id', 'amount_count', 'amount_mean', 'amount_std', \n",
    "                      'amount_max', 'amount_sum', 'merchant_name_nunique', \n",
    "                      'merchant_category_nunique']\n",
    "    \n",
    "    # Join with user data\n",
    "    user_feats = tx_agg.merge(\n",
    "        users_df[['id', 'credit_limit', 'credit_balance']], \n",
    "        left_on='user_id', \n",
    "        right_on='id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    if 'id' in user_feats.columns:\n",
    "        user_feats = user_feats.drop(columns=['id'])\n",
    "    \n",
    "    # Calculate credit utilization\n",
    "    user_feats['credit_limit'] = pd.to_numeric(user_feats['credit_limit'], errors='coerce').fillna(0)\n",
    "    user_feats['credit_balance'] = pd.to_numeric(user_feats['credit_balance'], errors='coerce').fillna(0)\n",
    "    user_feats['credit_utilization'] = np.where(\n",
    "        user_feats['credit_limit'] > 0,\n",
    "        user_feats['credit_balance'] / user_feats['credit_limit'],\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    user_feats = user_feats.fillna(0)\n",
    "    return user_feats\n",
    "\n",
    "user_features = build_user_features(users_df, transactions_df)\n",
    "print(f'âœ… Built features for {len(user_features)} users')\n",
    "print(f'   Features: {list(user_features.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alert type columns\n",
    "ALERT_TYPES = [\n",
    "    'alert_high_spender',\n",
    "    'alert_high_tx_volume',\n",
    "    'alert_high_merchant_diversity',\n",
    "    'alert_near_credit_limit',\n",
    "    'alert_large_transaction',\n",
    "    'alert_new_merchant',\n",
    "    'alert_location_based',\n",
    "    'alert_subscription_monitoring'\n",
    "]\n",
    "\n",
    "def generate_heuristic_labels(df):\n",
    "    \"\"\"Generate alert labels based on behavioral heuristics\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # High spender: top 25% by total spending\n",
    "    df['alert_high_spender'] = (df['amount_sum'] >= df['amount_sum'].quantile(0.75)).astype(int)\n",
    "    \n",
    "    # High transaction volume: top 25% by transaction count\n",
    "    df['alert_high_tx_volume'] = (df['amount_count'] >= df['amount_count'].quantile(0.75)).astype(int)\n",
    "    \n",
    "    # High merchant diversity: top 25% by unique merchants\n",
    "    df['alert_high_merchant_diversity'] = (df['merchant_name_nunique'] >= df['merchant_name_nunique'].quantile(0.75)).astype(int)\n",
    "    \n",
    "    # Near credit limit: utilization >= 70%\n",
    "    df['alert_near_credit_limit'] = (df['credit_utilization'] >= 0.7).astype(int)\n",
    "    \n",
    "    # Large transaction: max transaction > 75th percentile\n",
    "    df['alert_large_transaction'] = (df['amount_max'] >= df['amount_max'].quantile(0.75)).astype(int)\n",
    "    \n",
    "    # Defaults for other types\n",
    "    df['alert_new_merchant'] = 0\n",
    "    df['alert_location_based'] = 0\n",
    "    df['alert_subscription_monitoring'] = 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "if use_real_alerts and user_alerts_df is not None:\n",
    "    # Use real alert labels\n",
    "    pivot = user_alerts_df.pivot_table(\n",
    "        index='user_id',\n",
    "        columns='alert_type',\n",
    "        values='enabled',\n",
    "        fill_value=0,\n",
    "        aggfunc='max'\n",
    "    )\n",
    "    pivot.columns = [f'alert_{col}' if not col.startswith('alert_') else col for col in pivot.columns]\n",
    "    pivot = pivot.reset_index()\n",
    "    \n",
    "    user_features_with_labels = user_features.merge(pivot, on='user_id', how='left')\n",
    "    for alert_type in ALERT_TYPES:\n",
    "        if alert_type in user_features_with_labels.columns:\n",
    "            user_features_with_labels[alert_type] = user_features_with_labels[alert_type].fillna(0).astype(int)\n",
    "        else:\n",
    "            user_features_with_labels[alert_type] = 0\n",
    "    \n",
    "    print('âœ… Using real alert labels from data')\n",
    "else:\n",
    "    # Use heuristic labels\n",
    "    user_features_with_labels = generate_heuristic_labels(user_features)\n",
    "    print('âœ… Generated heuristic-based alert labels')\n",
    "\n",
    "# Show alert distribution\n",
    "print('\\nðŸ“Š Alert distribution:')\n",
    "for alert_type in ALERT_TYPES:\n",
    "    if alert_type in user_features_with_labels.columns:\n",
    "        count = user_features_with_labels[alert_type].sum()\n",
    "        pct = (count / len(user_features_with_labels)) * 100\n",
    "        print(f'   {alert_type}: {int(count)} users ({pct:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Train KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns for similarity calculation\n",
    "FEATURE_COLUMNS = [\n",
    "    'amount_mean', 'amount_std', 'amount_max', 'amount_sum', 'amount_count',\n",
    "    'merchant_name_nunique', 'merchant_category_nunique',\n",
    "    'credit_limit', 'credit_balance', 'credit_utilization'\n",
    "]\n",
    "\n",
    "# Prepare training data\n",
    "X = user_features_with_labels[FEATURE_COLUMNS].values\n",
    "y = user_features_with_labels[ALERT_TYPES].values\n",
    "user_ids = user_features_with_labels['user_id'].values\n",
    "\n",
    "print(f'Training data shape:')\n",
    "print(f'   X (features): {X.shape}')\n",
    "print(f'   y (labels): {y.shape}')\n",
    "print(f'   Users: {len(user_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print('âœ… Features normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN model\n",
    "knn_model = NearestNeighbors(\n",
    "    n_neighbors=min(N_NEIGHBORS, len(X_scaled)),\n",
    "    metric=METRIC,\n",
    "    algorithm='brute'\n",
    ")\n",
    "knn_model.fit(X_scaled)\n",
    "\n",
    "print(f'âœ… KNN model trained')\n",
    "print(f'   Algorithm: {knn_model.algorithm}')\n",
    "print(f'   Metric: {knn_model.metric}')\n",
    "print(f'   N neighbors: {knn_model.n_neighbors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model components\n",
    "model_artifacts = {\n",
    "    'knn_model': knn_model,\n",
    "    'scaler': scaler,\n",
    "    'feature_columns': FEATURE_COLUMNS,\n",
    "    'alert_types': ALERT_TYPES,\n",
    "    'user_ids': user_ids,\n",
    "    'alert_labels': y,\n",
    "    'training_features': X_scaled\n",
    "}\n",
    "\n",
    "with open('models/model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_artifacts, f)\n",
    "\n",
    "print('âœ… Model saved to models/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_version': MODEL_VERSION,\n",
    "    'data_version': DATA_VERSION,\n",
    "    'trained_at': datetime.now().isoformat(),\n",
    "    'n_users': len(user_ids),\n",
    "    'n_neighbors': N_NEIGHBORS,\n",
    "    'metric': METRIC,\n",
    "    'feature_columns': FEATURE_COLUMNS,\n",
    "    'alert_types': ALERT_TYPES,\n",
    "    'use_real_alerts': use_real_alerts,\n",
    "    'model_size_bytes': os.path.getsize('models/model.pkl')\n",
    "}\n",
    "\n",
    "with open('models/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print('âœ… Metadata saved to models/model_metadata.json')\n",
    "print(f'\\nModel metadata:')\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test recommendation for a sample user\n",
    "if len(user_ids) > 0:\n",
    "    test_user_idx = 0\n",
    "    test_user_id = user_ids[test_user_idx]\n",
    "    test_features = X_scaled[test_user_idx:test_user_idx+1]\n",
    "    \n",
    "    # Find similar users\n",
    "    distances, indices = knn_model.kneighbors(test_features, n_neighbors=N_NEIGHBORS)\n",
    "    \n",
    "    print(f'ðŸ§ª Test: Similar users to {test_user_id}:')\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        similar_user_id = user_ids[idx]\n",
    "        print(f'   {similar_user_id}: distance={dist:.3f}')\n",
    "    \n",
    "    # Generate recommendations\n",
    "    similar_labels = y[indices[0]]\n",
    "    probabilities = similar_labels.mean(axis=0)\n",
    "    \n",
    "    print(f'\\nðŸ“‹ Recommended alerts for {test_user_id}:')\n",
    "    for alert_type, prob in zip(ALERT_TYPES, probabilities):\n",
    "        if prob >= 0.4:\n",
    "            print(f'   {alert_type}: {prob:.2%} probability')\n",
    "\n",
    "print('\\nâœ… Training notebook completed successfully!')\n",
    "print('\\nNext step: Run notebook 2 to save model to MinIO')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
